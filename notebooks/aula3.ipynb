{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3\n",
    "Caso Pratico: Previsao do Consumo de Energia Eletrica na regiao Sudeste (SE)\n",
    "- Fonte: http://ipeadata.gov.br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import kstest\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpmdarima\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/usp-ds-series-temporais-TQD3F751/lib/python3.11/site-packages/pmdarima/__init__.py:52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Stuff we want at top-level\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_arima, ARIMA, AutoARIMA, StepwiseContext, decompose\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m acf, autocorr_plot, c, pacf, plot_acf, plot_pacf, \\\n\u001b[1;32m     54\u001b[0m     tsdisplay\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/usp-ds-series-temporais-TQD3F751/lib/python3.11/site-packages/pmdarima/arima/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapprox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/usp-ds-series-temporais-TQD3F751/lib/python3.11/site-packages/pmdarima/arima/approx.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# R approx function\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m c, check_endog\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_callable\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/usp-ds-series-temporais-TQD3F751/lib/python3.11/site-packages/pmdarima/utils/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Author: Taylor Smith <taylor.smith@alkaline-ml.com>\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/usp-ds-series-temporais-TQD3F751/lib/python3.11/site-packages/pmdarima/utils/array.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTYPE\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m C_intgrt_vec\n\u001b[1;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas_series\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_iterable\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m ]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_series\u001b[39m(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[0;32mpmdarima/utils/_array.pyx:1\u001b[0m, in \u001b[0;36minit pmdarima.utils._array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caso nao tenha instalado\n",
    "# !pip install ipeadatapy \n",
    "import ipeadatapy as ip\n",
    "\n",
    "ip.list_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preciso saber o codigo da serie temporal no site do IPEA\n",
    "## para esta serie o codigo e dado a seguir\n",
    "ip.describe('ELETRO12_CEESE12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[124]: verificando os dados\n",
    "cons_sudeste=ip.timeseries('ELETRO12_CEESE12')\n",
    "cons_sudeste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[125]: colhendo os dados da serie do consumo de energia em GWh\n",
    "consumo = pd.Series(cons_sudeste.iloc[:, 5].values, \n",
    "                    index=pd.date_range(start='1979-01-01', periods=len(cons_sudeste), \n",
    "                                        freq='ME'))\n",
    "\n",
    "# In[126]: Plotando o grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(consumo)\n",
    "plt.title(\"Energia elétrica referente ao consumo na região Sudeste (SE) - GWh\")\n",
    "plt.xlabel(\"Meses - jan/1979 a jun/2024\")\n",
    "plt.ylabel(\"GWh\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[127]: separando a serie tem dados de treino e teste\n",
    "\n",
    "# Definir as datas para separar treino e teste\n",
    "# data de corte escolhida\n",
    "\n",
    "data_corte=\"2022-06-01\"\n",
    "\n",
    "# Separar a série em treino e teste usando as datas\n",
    "energia_treino = consumo['1979-01-01':'2022-06-01']\n",
    "energia_teste = consumo['2022-07-01':'2024-07-01']\n",
    "print(energia_treino)\n",
    "print(energia_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os tamanhos dos períodos de treino e teste\n",
    "print(f\"Período de Treino: {energia_treino.index.min()} até {energia_treino.index.max()} - {len(energia_treino)} registros\")\n",
    "print(f\"Período de Teste: {energia_teste.index.min()} até {energia_teste.index.max()} - {len(energia_teste)} registros\")\n",
    "\n",
    "# In[128]: Plotar os períodos de treino e teste\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(energia_treino, label='Treino', color='blue')\n",
    "plt.plot(energia_teste, label='Teste', color='red')\n",
    "plt.axvline(pd.to_datetime(data_corte), color='black', linestyle='--', label='Data de Corte')\n",
    "plt.title('Separação da Série Temporal em Treino e Teste')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo os dados a partir de um arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a base de dados\n",
    "energia = pd.read_excel(\"/home/cairo/code/usp-ds-series-temporais/data/energia.xlsx\")\n",
    "\n",
    "# Lendo a base de dados\n",
    "print(energia.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_energia = pd.Series(energia.iloc[:, 1].values, \n",
    "                    index=pd.date_range(start='1979-01-01', periods=len(energia), \n",
    "                                        freq='ME'))\n",
    "cons_energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[130]: Plotando o grafico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cons_energia)\n",
    "plt.title(\"Energia eletrica referente ao consumo na regiao Sudeste (SE) - GWh\")\n",
    "plt.xlabel(\"Meses - jan/1979 a jun/2024\")\n",
    "plt.ylabel(\"GWh\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos rodar todos os modelos para a serie de energia do Sudeste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturar avisos de convergência e tratá-los\n",
    "warnings.filterwarnings(\"error\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[132]: Carregar os dados de energia e garantir que não há valores ausentes\n",
    "energia = pd.read_excel(\"/home/cairo/code/usp-ds-series-temporais/data/energia.xlsx\", usecols=[1]).dropna()\n",
    "\n",
    "# In[133]: Criar a série temporal a partir de 1979 com frequência mensal\n",
    "energia.index = pd.date_range(start='1979-01', periods=len(energia), freq='ME')\n",
    "energia = energia.squeeze()  # Converter para uma Series\n",
    "\n",
    "# In[134]: Separar a base de dados em treino e teste\n",
    "benergia = energia[:'2022-06'].ffill()  # Preencher valores nulos com forward fill\n",
    "reaisenergia = energia['2022-07':'2024-06']  # Teste de 2022-07 até 2024-06\n",
    "\n",
    "# In[135]: Converter explicitamente para tipo numérico e garantir que são floats\n",
    "benergia = pd.to_numeric(benergia, errors='coerce').astype(float)\n",
    "\n",
    "# In[136]: Lista para armazenar os modelos, MAPE e previsões\n",
    "modelos_energia = []\n",
    "mapes_energia = []\n",
    "previsoes_energia = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_forecast = pd.Series([benergia.iloc[-1]] * len(reaisenergia), index=reaisenergia.index)\n",
    "mape_naive = mape(reaisenergia, naive_forecast) * 100\n",
    "modelos_energia.append(\"Naive\")\n",
    "mapes_energia.append(mape_naive)\n",
    "previsoes_energia[\"Naive\"] = naive_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Mean (média)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_forecast = pd.Series(benergia.mean(), index=reaisenergia.index)\n",
    "mape_mean = mape(reaisenergia, mean_forecast) * 100\n",
    "modelos_energia.append(\"Mean\")\n",
    "mapes_energia.append(mape_mean)\n",
    "previsoes_energia[\"Mean\"] = mean_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(benergia)\n",
    "drift_slope = (benergia.iloc[-1] - benergia.iloc[0]) / (n - 1)\n",
    "drift_forecast = benergia.iloc[-1] + drift_slope * np.arange(1, len(reaisenergia) + 1)\n",
    "drift_forecast = pd.Series(drift_forecast, index=reaisenergia.index)\n",
    "mape_drift_result = mape(reaisenergia, drift_forecast) * 100\n",
    "modelos_energia.append(\"Drift\")\n",
    "mapes_energia.append(mape_drift_result)\n",
    "previsoes_energia[\"Drift\"] = drift_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Naive Sazonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_sazonal_forecast = pd.Series([benergia.iloc[-12 + (i % 12)]\n",
    "                                    for i in range(len(reaisenergia))],\n",
    "                                   index=reaisenergia.index)\n",
    "mape_naive_sazonal = mape(reaisenergia, naive_sazonal_forecast) * 100\n",
    "modelos_energia.append(\"Naive Sazonal\")\n",
    "mapes_energia.append(mape_naive_sazonal)\n",
    "previsoes_energia[\"Naive Sazonal\"] = naive_sazonal_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suavização Exponencial Simples (SES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_model = SimpleExpSmoothing(benergia).fit(optimized=True)\n",
    "ses_forecast = ses_model.forecast(steps=len(reaisenergia))\n",
    "mape_ses = mape(reaisenergia, ses_forecast) * 100\n",
    "modelos_energia.append(\"SES\")\n",
    "mapes_energia.append(mape_ses)\n",
    "previsoes_energia[\"SES\"] = ses_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt-Winters Aditivo - Ajustar inicialização e Box-Cox para melhorar a convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    hw_add_model = ExponentialSmoothing(\n",
    "        benergia,\n",
    "        seasonal_periods=12,\n",
    "        trend='add',\n",
    "        seasonal='add',\n",
    "        initialization_method=\"estimated\",  # Método robusto de inicialização\n",
    "        use_boxcox=True  # Tentar estabilizar a variância com Box-Cox\n",
    "    ).fit(optimized=True)\n",
    "    \n",
    "    hw_add_forecast = hw_add_model.forecast(steps=len(reaisenergia))\n",
    "    mape_hw_add = mape(reaisenergia, hw_add_forecast) * 100\n",
    "    modelos_energia.append(\"Holt-Winters Aditivo\")\n",
    "    mapes_energia.append(mape_hw_add)\n",
    "    previsoes_energia[\"Holt-Winters Aditivo\"] = hw_add_forecast\n",
    "except Exception:\n",
    "    modelos_energia.append(\"Holt-Winters Aditivo\")\n",
    "    mapes_energia.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt-Winters Multiplicativo - Ajustar inicialização e Box-Cox para melhorar a convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    hw_mult_model = ExponentialSmoothing(\n",
    "        benergia,\n",
    "        seasonal_periods=12,\n",
    "        trend='add',\n",
    "        seasonal='mul',\n",
    "        initialization_method=\"estimated\",  # Método robusto de inicialização\n",
    "        use_boxcox=True  # Tentar estabilizar a variância com Box-Cox\n",
    "    ).fit(optimized=True)\n",
    "    \n",
    "    hw_mult_forecast = hw_mult_model.forecast(steps=len(reaisenergia))\n",
    "    mape_hw_mult = mape(reaisenergia, hw_mult_forecast) * 100\n",
    "    modelos_energia.append(\"Holt-Winters Multiplicativo\")\n",
    "    mapes_energia.append(mape_hw_mult)\n",
    "    previsoes_energia[\"Holt-Winters Multiplicativo\"] = hw_mult_forecast\n",
    "except Exception:\n",
    "    modelos_energia.append(\"Holt-Winters Multiplicativo\")\n",
    "    mapes_energia.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação dos modelos com base no MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_comparison = pd.DataFrame({'Modelo': modelos_energia, 'MAPE': mapes_energia})\n",
    "mape_comparison = mape_comparison.sort_values(by='MAPE', ascending=True).reset_index(drop=True)\n",
    "print(mape_comparison)\n",
    "\n",
    "# In[145]: Gráfico dos MAPE dos modelos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(mape_comparison['Modelo'], mape_comparison['MAPE'], color='skyblue')\n",
    "plt.xlabel(\"MAPE\")\n",
    "plt.title(\"MAPE Comparação de Modelos\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[146]: Selecionar o modelo com o menor MAPE\n",
    "melhor_modelo = mape_comparison.loc[0, 'Modelo']\n",
    "melhores_previsoes = previsoes_energia[melhor_modelo]\n",
    "\n",
    "# In[147]: Criar gráfico comparando os valores reais e previstos do melhor modelo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(reaisenergia.index, reaisenergia, label='Valores Reais', color='blue')\n",
    "plt.plot(reaisenergia.index, melhores_previsoes, label=f'Previsão - {melhor_modelo}', color='red')\n",
    "plt.title(f'Valores Reais vs Previsão ({melhor_modelo})')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valores')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de normalidade e Ljung-Box para os resíduos do melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = reaisenergia - melhores_previsoes\n",
    "\n",
    "# In[149]: Teste de normalidade Shapiro-Wilk\n",
    "stat, p_value_shapiro = shapiro(residuos)\n",
    "print(f\"Teste de Normalidade Shapiro-Wilk: Estatística={stat:.4f}, p-valor={p_value_shapiro:.4f}\")\n",
    "if p_value_shapiro > 0.05:\n",
    "    print(\"Os resíduos parecem seguir uma distribuição normal (não rejeitamos H0).\")\n",
    "else:\n",
    "    print(\"Os resíduos não seguem uma distribuição normal (rejeitamos H0).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[150]: Teste de Ljung-Box para autocorrelação dos resíduos\n",
    "lb_test = acorr_ljungbox(residuos, lags=[10], return_df=True)\n",
    "print(f\"Teste Ljung-Box:\\n{lb_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[151]: Interpretação do teste de Ljung-Box\n",
    "p_value_ljungbox = lb_test['lb_pvalue'].values[0]\n",
    "if p_value_ljungbox > 0.05:\n",
    "    print(\"Não há evidências de autocorrelação significativa nos resíduos (não rejeitamos H0).\")\n",
    "else:\n",
    "    print(\"Há evidências de autocorrelação nos resíduos (rejeitamos H0).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos ARIMA - (Box - Jenkins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELOS ARIMA - Simulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulação de um modelo AR(1)\n",
    "# Definir o coeficiente do modelo AR(1)\n",
    "ar = np.array([1, -0.8])\n",
    "\n",
    "# AR(1) com coeficiente +0.8 (note o sinal negativo para simulação)\n",
    "# a biblioteca ArmaProcess espera que o sinal seja inverso\n",
    "ma = np.array([1])  # Não há parte MA, então é apenas [1]\n",
    "\n",
    "# Criar o processo AR(1)\n",
    "ar_process = ArmaProcess(ar, ma)\n",
    "\n",
    "# Simular 500 pontos para a série temporal\n",
    "np.random.seed(42)  # Para reprodutibilidade\n",
    "serie_ar = ar_process.generate_sample(nsample=500)\n",
    "\n",
    "# In[154]: Plotar a série temporal simulada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(serie_ar)\n",
    "plt.title('Modelo AR(1) X(t)=0.8.X(t-1) + erro(t)')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valores simulados')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[155]: Definir o coeficiente do modelo MA(1)\n",
    "ma = np.array([1, -0.3])  # MA(1) com coeficiente -0.3\n",
    "ar = np.array([1])  # Não há parte AR, então é apenas [1]\n",
    "\n",
    "# Criar o processo MA(1)\n",
    "ma_process = ArmaProcess(ar, ma)\n",
    "\n",
    "# Simular 500 pontos para a série temporal\n",
    "np.random.seed(42)  # Para reprodutibilidade\n",
    "serie_ma = ma_process.generate_sample(nsample=500)\n",
    "\n",
    "# In[156]: Plotar a série temporal simulada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(serie_ma)\n",
    "plt.title('Modelo MA(1) X(t)=-0.3erro(t-1) + erro(t)')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valores simulados')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[157]: Simulação de um modelo ARMA(1,1)\n",
    "# Definir os coeficientes do modelo ARMA(1,1)\n",
    "ar = np.array([1, -0.8])  # AR(1) com coeficiente +0.8\n",
    "ma = np.array([1, -0.3])  # MA(1) com coeficiente -0.3\n",
    "\n",
    "# Criar o processo ARMA(1,1)\n",
    "arma_process = ArmaProcess(ar, ma)\n",
    "\n",
    "# Simular 500 pontos para a série temporal\n",
    "np.random.seed(42)  # Para reprodutibilidade\n",
    "serie_arma = arma_process.generate_sample(nsample=500)\n",
    "\n",
    "# In[158]: Plotar a série temporal simulada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(serie_arma)\n",
    "plt.title('Simulação do Modelo ARMA(1,1) com AR=0.8 e MA=-0.3')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valores simulados')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[159]: Simulando um modelo ARIMA(1,1,1)\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Definir o número de pontos para simulação\n",
    "pontos = 500\n",
    "\n",
    "# Definir os parâmetros ARIMA (1,1,1)\n",
    "ar = np.array([1, -0.8])   \n",
    "ma = np.array([1, -0.3])   \n",
    " \n",
    "# Simular a série temporal ARIMA(1,1,1)\n",
    "np.random.seed(42)  # Para reprodutibilidade\n",
    "arma_process = ArmaProcess(ar, ma)\n",
    "serie_arima = arma_process.generate_sample(nsample=pontos)\n",
    "\n",
    "# Converter a série estacionária em uma série não estacionária aplicando a integração (d=1)\n",
    "serie_arima_nao_estacionaria = np.cumsum(serie_arma)  # Diferenciação inversa (integração)\n",
    "\n",
    "# Converter a série simulada em um DataFrame\n",
    "serie_arima_nao_estacionaria = pd.Series(serie_arima_nao_estacionaria)\n",
    "\n",
    "# In[160]: Visualizar a série simulada não estacionária\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(serie_arima_nao_estacionaria)\n",
    "plt.title(\"Série Não Estacionária ARIMA(1,1,1)\")\n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando as séries autoregressivas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes de Estacionariedade\n",
    "\n",
    "- Teste de Dickey-Fuller\n",
    "- H0: A série Não é Estacionária\n",
    "- H1: A série é Estacionária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de Dickey-Fuller aumentado (ADF)\n",
    "def dickey_fuller_test(series, title=''):\n",
    "    result = adfuller(series)\n",
    "    print(f'Teste de Dickey-Fuller para {title}')\n",
    "    print(f'Estatística: {result[0]}')\n",
    "    print(f'p-valor: {result[1]}')\n",
    "    print('Critérios:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'{key}: {value}')\n",
    "    print('Conclusão:', 'Estacionária' if result[1] < 0.01 else 'Não Estacionária')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[162]: Aplicando o teste de Dickey-Fuller\n",
    "dickey_fuller_test(serie_ar, 'AR(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller_test(serie_ma, 'MA(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller_test(serie_arma, 'ARMA(1,1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATENÇÃO: vamos rodar para a série ARIMA, tem o I = 1\n",
    "dickey_fuller_test(serie_arima_nao_estacionaria, 'ARIMA(1,1,1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimação de um modelo ARIMA - Escolher, p, q e d\n",
    "### Funções ACF e PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> continuar 2:01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf_pacf(series, lags=20, title=''):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    plot_acf(series, lags=lags, ax=ax[0], title=f'ACF {title}')\n",
    "    plot_pacf(series, lags=lags, ax=ax[1], title=f'PACF {title}', method='ywm')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[164]: Plotando ACF e PACF das séries\n",
    "plot_acf_pacf(serie_ar, title='AR(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf(serie_ma, title='MA(1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf(serie_arma, title='ARMA(1,1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf(serie_arima_nao_estacionaria, title='ARIMA(1,1,1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimando o modelo ARIMA usando auto-arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar automaticamente o modelo ARIMA\n",
    "# Lembrando: simulamos um AR(1) de coeficiente 0.8\n",
    "auto_arima_model = auto_arima(serie_ar, trace=True, seasonal=False, stepwise=True)\n",
    "print(auto_arima_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lembrando: simulamos um MA(1) de coeficiente -0.3\n",
    "auto_arima_model_ma = auto_arima(serie_ma, trace=True, seasonal=False, stepwise=True)\n",
    "print(auto_arima_model_ma.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lembrando: simulamos um ARMA(1,1) de coeficiente AR = 0.8 e MA= -0.3\n",
    "auto_arima_model_arma = auto_arima(serie_arma, trace=True, seasonal=False, stepwise=True)\n",
    "print(auto_arima_model_arma.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lembrando: simulamos um ARIMA(1,1,1) de coeficiente AR = 0.8 e MA= -0.3\n",
    "auto_arima_model_arima = auto_arima(serie_arima_nao_estacionaria, trace=True, seasonal=False, stepwise=True)\n",
    "\n",
    "print(auto_arima_model_arima.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para identificar quantas diferenciações são necessárias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simular_arima(n, ar=[1, -0.8], ma=[1, -0.3], d=1, noise_std=5):\n",
    "    \"\"\"Simula uma série ARIMA com tendência, maior variabilidade e componente não sazonal.\"\"\"\n",
    "    \n",
    "    # Criar a parte ARMA (ARIMA sem diferenciação)\n",
    "    ar_params = np.r_[1, -np.array(ar[1:])]  # Parâmetro AR ajustado para ARMAProcess\n",
    "    ma_params = np.r_[1, np.array(ma[1:])]   # Parâmetro MA ajustado para ARMAProcess\n",
    "    arma_process = ArmaProcess(ar_params, ma_params)\n",
    "    serie_arma = arma_process.generate_sample(nsample=n)\n",
    "    \n",
    "    # Adicionar um componente de tendência (para garantir que a série seja não estacionária)\n",
    "    tendencia = np.linspace(0, n * 0.05, n)  # Componente de tendência linear\n",
    "    \n",
    "    # Adicionar variabilidade adicional\n",
    "    variabilidade_adicional = np.random.normal(loc=0, scale=noise_std, size=n)  # Variabilidade adicional\n",
    "    \n",
    "    # Adicionar a tendência, variabilidade e aplicar a diferenciação (d=1)\n",
    "    serie_arima = np.cumsum(serie_arma + tendencia + variabilidade_adicional)  # Diferenciação inversa (integração)\n",
    "    \n",
    "    return pd.Series(serie_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[167]: Simular a série ARIMA(1,1,1) com tendência e variabilidade aumentada\n",
    "np.random.seed(42)\n",
    "serie_arima = simular_arima(500, ar=[1, -0.8], ma=[1, -0.3], d=1, noise_std=5)\n",
    "\n",
    "# In[168]: Visualizar a série simulada ARIMA(1,1,1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(serie_arima)\n",
    "plt.title(\"Série Simulada ARIMA(1,1,1) com Tendência e Variabilidade Aumentada\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[169]: Função para verificar quantas diferenciações são necessárias para tornar a série estacionária\n",
    "import pmdarima as pm\n",
    "def verificar_differenciacao(serie, nome):\n",
    "    # Usar a função ndiffs do pmdarima\n",
    "    d = pm.arima.ndiffs(serie, test='adf')  # Teste de Dickey-Fuller aumentado\n",
    "    print(f\"A série {nome} precisa de {d} diferenciação(ões) para ser estacionária.\")\n",
    "    return d\n",
    "\n",
    "# Verificar quantas diferenciações são necessárias\n",
    "verificar_differenciacao(serie_arima, \"ARIMA(1,1,1)\")\n",
    "\n",
    "# Verificar quantas diferenciações são necessárias\n",
    "verificar_differenciacao(serie_ar, \"AR(1)\")\n",
    "verificar_differenciacao(serie_ma, \"MA(1)\")\n",
    "verificar_differenciacao(serie_arma, \"ARMA(1,1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulação de séries AR de ordens maiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para simular séries AR, MA e ARIMA\n",
    "def simular_arima(ar=None, ma=None, n=500, d=1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    ar = np.array([1] + [-coef for coef in (ar if ar else [])])  # Definir AR\n",
    "    ma = np.array([1] + [coef for coef in (ma if ma else [])])  # Definir MA\n",
    "    process = ArmaProcess(ar, ma)\n",
    "    return process.generate_sample(nsample=n)\n",
    "\n",
    "# In[171]: simulando outras series de ordem superior\n",
    "\n",
    "serie_ar2 = simular_arima(ar=[0.8, 0.1], n=500)\n",
    "\n",
    "# In[172]: Plotar a série simulada AR(2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(serie_ar2)\n",
    "plt.title('Simulação do Modelo AR(2)')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valores simulados')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[173]: Simulando agora um AR(3)\n",
    "serie_ar3 = simular_arima(ar=[0.5, 0.1, 0.3], n=500)\n",
    "\n",
    "# In[174]: Plotar a série simulada AR(3)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(serie_ar3)\n",
    "plt.title('Simulação do Modelo AR(3)')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Valores simulados')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[175]: Teste Dickey-Fuller (ADF) para estacionariedade\n",
    "def teste_dickey_fuller(serie, nome):\n",
    "    resultado = adfuller(serie)\n",
    "    print(f\"\\nTeste Dickey-Fuller para {nome}:\")\n",
    "    print(f\"Estatística: {resultado[0]}\")\n",
    "    print(f\"P-valor: {resultado[1]}\")\n",
    "    for key, value in resultado[4].items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print('Conclusão:', 'Estacionária' if resultado[1] < 0.01 else 'Não Estacionária')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[176]: Verificar a estacionariedade das séries simuladas\n",
    "teste_dickey_fuller(serie_ar2, \"AR(2)\")\n",
    "\n",
    "teste_dickey_fuller(serie_ar3, \"AR(3)\")\n",
    "\n",
    "# In[177]: Plotando ACF e PACF para as séries simuladas\n",
    "plot_acf_pacf(serie_ar2, title='AR(2)')\n",
    "\n",
    "plot_acf_pacf(serie_ar3, title='AR(3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar modelos ARIMA diretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar ARIMA manualmente com ordem (2,0,0) para série 2 e (3,0,0) para série 3\n",
    "modelo_ar2 = ARIMA(serie_ar2, order=(2, 0, 0)).fit()\n",
    "print(f'\\nModelo ARIMA(2,0,0) ajustado para serie2:\\n{modelo_ar2.summary()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_ar3 = ARIMA(serie_ar3, order=(3, 0, 0)).fit()\n",
    "print(f'\\nModelo ARIMA(3,0,0) ajustado para serie3:\\n{modelo_ar3.summary()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[179]: Simular séries AR(3) com diferentes coeficientes positivos e negativos\n",
    "# AR(3) com coeficientes [0.5, -0.1, -0.3]\n",
    "serie_ar31 = simular_arima(ar=[0.5, -0.1, -0.3], n=500)\n",
    "\n",
    "# Plot ACF e PACF para serie2 (AR(3) com coeficientes [0.5, 0.1, 0.3])\n",
    "plot_acf_pacf(serie_ar31, title='AR(3) coef positivos e negativos')\n",
    "\n",
    "modelo_ar31 = ARIMA(serie_ar31, order=(3, 0, 0)).fit()\n",
    "print(f'\\nModelo ARIMA(3,0,0) ajustado para AR(3) com coef positivos e negativos:\\n{modelo_ar31.summary()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[180]: 4. Simular uma série ARMA(2,2)\n",
    "serie_arma221 = simular_arima(ar=[0.8, -0.1], ma=[0.4, -0.3], n=500)\n",
    "\n",
    "# Testar a estacionariedade de série ARMA(2,2)\n",
    "teste_dickey_fuller(serie_arma221, \"ARMA(2,2) coef positivos e negativos\")\n",
    "\n",
    "# Plotar ACF e PACF para série ARMA(2,2)\n",
    "plot_acf_pacf(serie_arma221, title='ARMA(2,2) coef positivos e negativos')\n",
    "\n",
    "### Caso encontre ARIMA(0,0,0) - não foi possível encontrar memória\n",
    "## autoregressiva significativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modelos ARIMA com Sazonalidade - SARIMA, possui os parâmetros P, D e Q Sazonais.\n",
    "- Fica SARIMA(p,d,q)(P,D,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando a série do Índice de Volume de Vendas de SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pelo pacote python bcb - Baixar dados do Sistema Gerador de Séries Temporais\n",
    "# do Banco Central\n",
    "\n",
    "# https://www3.bcb.gov.br/sgspub/localizarseries/localizarSeries.do?method=prepararTelaLocalizarSeries\n",
    "\n",
    "# Importa as bibliotecas\n",
    "\n",
    "# pip install python-bcb\n",
    " \n",
    "from bcb import sgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os dados da série do Índice de Volume de Vendas de SP do BCB\n",
    "varejo2 = sgs.get({'volume_vendas': 1475}, start='2000-01-01', end='2022-12-31')\n",
    "print(varejo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[182]: Certificar-se de que a série temporal está no formato correto (frequência mensal)\n",
    "varejo2.index = pd.to_datetime(varejo2.index)\n",
    "varejo2 = varejo2.asfreq('MS')\n",
    "print(varejo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[183]: Plot da série\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(varejo2, label='Volume de Vendas - SP')\n",
    "plt.title(\"Índice de Volume de Vendas de SP\")\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Índice')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[184]: Divisão da série em treino e teste\n",
    "varejotreino = varejo2[:'2020-12']\n",
    "varejoteste = varejo2['2021-01':]\n",
    "\n",
    "# Checagem do tamanho do conjunto de teste\n",
    "print(f\"Comprimento da série de teste: {len(varejoteste)}\")\n",
    "\n",
    "# In[185]:# Plotando as séries de treino e teste juntas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(varejo2, label='Varejo SP')\n",
    "plt.plot(varejotreino, label='Treino')\n",
    "plt.plot(varejoteste, label='Teste', color='blue')\n",
    "plt.title(\"Série Treinada e Testada\")\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Índice')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise da série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico ACF e PACF\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,4))\n",
    "plot_acf(varejotreino, lags=24, ax=axes[0])\n",
    "plot_pacf(varejotreino, lags=24, ax=axes[1], method='ywm')\n",
    "plt.show()\n",
    "\n",
    "# In[187]: Teste de Estacionariedade - ADF (Dickey-Fuller)\n",
    "result = adfuller(varejotreino.dropna())\n",
    "print(f'Resultado do Teste ADF: p-valor = {result[1]}')\n",
    "if result[1] < 0.05:\n",
    "    print(\"A série é estacionária.\")\n",
    "else:\n",
    "    print(\"A série não é estacionária.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[188]: Verificar quantas diferenciacoes sao necessarias\n",
    "verificar_differenciacao(varejotreino, \"Varejo - Treinamento\")\n",
    "\n",
    "# Diferenciação para estacionariedade\n",
    "varejotreino_diff = varejotreino.diff().dropna()\n",
    "\n",
    "# In[189]: Gráficos ACF e PACF da série diferenciada\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,4))\n",
    "plot_acf(varejotreino_diff, lags=24, ax=axes[0])\n",
    "plot_pacf(varejotreino_diff, lags=24, ax=axes[1], method='ywm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[190]: Ajuste do modelo ARIMA na série diferenciada (autoarima)\n",
    "arimavarejo = auto_arima(varejotreino_diff,\n",
    "                         seasonal=True,\n",
    "                         m=12,  # Periodicidade da sazonalidade\n",
    "                         trace=True,\n",
    "                         stepwise=True)\n",
    "\n",
    "# Exibir o resumo do modelo ajustado\n",
    "print(arimavarejo.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação e Diagnóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resíduos do modelo\n",
    "residuos_arima = arimavarejo.resid()\n",
    "print(f\"Resíduos do modelo: {residuos_arima}\")\n",
    "\n",
    "# In[192]: 1. Teste de Ljung-Box para verificar autocorrelação dos resíduos\n",
    "ljung_box = sm.stats.acorr_ljungbox(residuos_arima, lags=[10], return_df=True)\n",
    "print(f'Resultado do teste de Ljung-Box:\\n{ljung_box}')\n",
    "# Se p-value > 0.05, resíduos não são correlacionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat, p_value = kstest(residuos_arima, 'norm', args=(np.mean(residuos_arima), np.std(residuos_arima)))\n",
    "print(f'Teste de Kolmogorov-Smirnov para normalidade: p-valor = {p_value}')\n",
    "if p_value > 0.01:\n",
    "    print(\"Os resíduos seguem uma distribuição normal.\")\n",
    "else:\n",
    "    print(\"Os resíduos não seguem uma distribuição normal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste ARCH para verificar heterocedasticidade dos resíduos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install arch\n",
    "\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = arch_model(residuos_arima, vol='ARCH', p=1)\n",
    "test_arch = am.fit(disp='off')\n",
    "print(test_arch.summary())\n",
    "#se p-value > 0.05 - nao ha efeitos ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[195]: Prever 24 passos à frente na série diferenciada\n",
    "n_periods = 24\n",
    "previsoes_diff = arimavarejo.predict(n_periods=n_periods)\n",
    "print(f\"Previsões diferenciadas: {previsoes_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[196]: Índices das previsões (mesmo formato de data da série de treino e teste)\n",
    "index_of_fc = pd.date_range(varejotreino.index[-1], periods=n_periods+1, freq='MS')[1:]\n",
    "\n",
    "# In[197]: Para voltar ao nível original:\n",
    "# Iterar para reverter a diferenciação das previsões\n",
    "ultimo_valor_original = varejotreino.iloc[-1] # Último valor conhecido da série original (não diferenciada)\n",
    "previsoes_nivel_original = [ultimo_valor_original]\n",
    "print(ultimo_valor_original)\n",
    "print(previsoes_nivel_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[198]: Somar as previsões diferenciadas ao último valor conhecido da série original\n",
    "for previsao in previsoes_diff:\n",
    "    novo_valor = previsoes_nivel_original[-1] + previsao\n",
    "    previsoes_nivel_original.append(novo_valor)\n",
    "\n",
    "# In[199]: Remover o primeiro valor, pois é o último valor conhecido da série original\n",
    "previsoes_nivel_original = previsoes_nivel_original[1:]\n",
    "print(previsoes_nivel_original)\n",
    "\n",
    "# In[200]: Converter previsões de volta para uma Série Pandas com o índice correto\n",
    "previsoes_nivel_original_series = pd.Series(previsoes_nivel_original, index=index_of_fc)\n",
    "print(previsoes_nivel_original_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[201]: Plotando as previsões no nível original junto com a série de treino e teste\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(varejotreino, label='Treino')\n",
    "plt.plot(varejoteste, label='Teste', color='blue')\n",
    "plt.plot(previsoes_nivel_original_series, label='Previsão ARIMA - Nível Original', color='orange')\n",
    "plt.legend()\n",
    "plt.title('Previsão ARIMA para Varejo SP (24 Passos à Frente - Nível Original)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[202]: Garantir que as previsões e os valores reais estejam alinhados para o MAPE\n",
    "previsoes_series_alinhadas = previsoes_nivel_original_series[:len(varejoteste)].dropna()\n",
    "varejoteste_alinhada = varejoteste.loc[previsoes_series_alinhadas.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[203]: Calcular o MAPE\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = mean_absolute_percentage_error(varejoteste_alinhada, previsoes_series_alinhadas)*100\n",
    "print(f'MAPE: {mape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install arch\n",
    "\n",
    "# In[204]: Ajustar o modelo ETS (Holt-Winters Exponential Smoothing) - para serie varejotreino\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n",
    "from arch import arch_model\n",
    "from scipy.stats import kstest\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_model = ExponentialSmoothing(varejotreino, seasonal='add', trend='add', seasonal_periods=12).fit()\n",
    "\n",
    "# In[205]: Previsões para os próximos 24 passos\n",
    "ets_forecast = ets_model.forecast(steps=24)\n",
    "print(f'Previsões ETS: {ets_forecast}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[206]: Plotando os valores reais e as previsões\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(varejotreino, label='Treino')\n",
    "plt.plot(varejoteste, label='Teste', color='blue')\n",
    "plt.plot(ets_forecast, label='Previsão ETS', color='orange')\n",
    "plt.legend()\n",
    "plt.title('Previsão ETS - 24 Passos à Frente')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[207]: Avaliação do desempenho do modelo usando MAPE\n",
    "mape_ets = mape(varejoteste, ets_forecast[:len(varejoteste)])*100\n",
    "print(f'MAPE ETS: {mape_ets}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevendo a Inflação - IPCA - BACEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "#from statsmodels.tsa.stattools import acf, pacf\n",
    "# pip install pmdarima\n",
    "# from pmdarima import auto_arima\n",
    "# from sklearn.metrics import mean_absolute_percentage_error\n",
    "# from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "# from scipy import stats\n",
    "# pip install arch\n",
    "# from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca = sgs.get({'ipca': 433}, start='2000-01-01', end='2024-08-31')\n",
    "print(ipca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[209]: Dividindo em série de treino (sipca) e teste (teste)\n",
    "sipca = ipca[:'2023-08']\n",
    "teste = ipca['2023-09':'2024-08']\n",
    "\n",
    "# In[210]: Plotando as séries de treino e teste juntas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(ipca, label='IPCA')\n",
    "plt.plot(sipca, label='IPCA Treino')\n",
    "plt.plot(teste, label='Teste', color='blue')\n",
    "plt.title(\"Série Treinada e Testada\")\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Inflacao')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipca['Ano'] = ipca.index.year\n",
    "ipca['Mês'] = ipca.index.month\n",
    "\n",
    "# In[211]: Fazer o Gráfico com destaque para valores mensais\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='Mês', y='ipca', data=ipca, palette='viridis')\n",
    "plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.title('Distribuição Mensal do IPCA (2000-2024)')\n",
    "plt.xlabel('Mês')\n",
    "plt.ylabel('Valores do IPCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando a série com gráficos de ACF e PACF\n",
    "plot_acf(sipca)\n",
    "plot_pacf(sipca, method='ywm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[213]: Estimando o modelo ARIMA(1,0,0)(0,0,1)[12] com sazonalidade\n",
    "# Certifique-se de que seu índice é um DatetimeIndex com frequência\n",
    "sipca.index = pd.to_datetime(sipca.index)\n",
    "\n",
    "# Se necessário, definir explicitamente a frequência, por exemplo, mensal ('MS')\n",
    "sipca = sipca.asfreq('MS')  # MS é o padrão para início de cada mês\n",
    "\n",
    "# Ajuste do modelo ARIMA com ordem sazonal\n",
    "mod = ARIMA(sipca, order=(1, 0, 0), seasonal_order=(0, 0, 1, 12)).fit()\n",
    "\n",
    "# Exibir o resumo do modelo ajustado\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[214]: Usando auto_arima para encontrar o melhor modelo\n",
    "modelo = auto_arima(sipca, seasonal=True, m=12, trace=True)\n",
    "\n",
    "# Fazendo a previsão do modelo com sazonalidade\n",
    "pipca = mod.get_forecast(steps=12)\n",
    "pipca_mean = pipca.predicted_mean\n",
    "\n",
    "# Fazendo a previsão do modelo auto_arima\n",
    "psipca = modelo.predict(n_periods=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[215]: Plotando as previsões\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sipca, label='Treino')\n",
    "plt.plot(teste, label='Teste', color='blue')\n",
    "plt.plot(pd.Series(pipca_mean, index=teste.index), label='Previsão ARIMA Sazonal', color='orange')\n",
    "plt.plot(pd.Series(psipca, index=teste.index), label='Previsão Auto ARIMA', color='green')\n",
    "plt.legend()\n",
    "plt.title('Previsões ARIMA Sazonal e Auto ARIMA')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[216]: Fazendo o grafico somente com os valores previstos e reais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(teste, label='Valores Reais (Teste)', color='blue')\n",
    "plt.plot(pd.Series(pipca_mean, index=teste.index), label='Previsão ARIMA Sazonal', color='orange')\n",
    "plt.plot(pd.Series(psipca, index=teste.index), label='Previsão Auto ARIMA', color='green')\n",
    "plt.legend()\n",
    "plt.title('Comparação entre Valores Reais e Previsões (ARIMA Sazonal e Auto ARIMA)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[217]: Avaliação da acurácia das previsões\n",
    "mape_pipca = mean_absolute_percentage_error(teste, pipca_mean)*100\n",
    "mape_psipca = mean_absolute_percentage_error(teste, psipca)*100\n",
    "print(f'MAPE Previsão ARIMA Sazonal: {mape_pipca}')\n",
    "print(f'MAPE Previsão Auto ARIMA: {mape_psipca}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[218]: Verificando os resíduos\n",
    "residuals = mod.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos um modelo definido precisamos saber se o modelo capturou toda a estrutura do processo.\n",
    "Significa que devemos checar se os resíduos do modelo estão limpos quer dizer, devemos ter resíduos não autocorrelacionados e normalmente distribuídos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Teste se os resíduos são não autocorrelacionados\n",
    "- Teste de Ljung-Box\n",
    "- H0: independência da ST, isto é, resíduos não correlacionados no tempo\n",
    "- H1: dependência da ST, isto é, resíduos correlacionados, indicando que o modelo não capturou alguma estrutura que indica um erro sistemático\n",
    "- Teste de Ljung-Box para independência dos resíduos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ljung_box = acorr_ljungbox(residuals, lags=[12], return_df=True)\n",
    "print(ljung_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Teste de Normalidade dos Resíduos\n",
    "- Teste de Kolmogorv-Smirnov\n",
    "- H0: Resíduos com comportamento normal\n",
    "- H1: Resíduos sem normalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de normalidade dos resíduos (Kolmogorov-Smirnov)\n",
    "ks_stat, ks_p_value = stats.kstest(residuals, 'norm', args=(np.mean(residuals), np.std(residuals)))\n",
    "print(f'Teste de Kolmogorov-Smirnov: p-value = {ks_p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testar a estacionariedade da variância\n",
    "- testar se existe efeitos ARCH\n",
    "- H0: Não Existe Efeitos ARCH\n",
    "- H1: Existe Efeitos ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de efeitos ARCH nos resíduos\n",
    "arch_test = arch_model(residuals,rescale=False).fit()\n",
    "print(arch_test.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando agora as previsoes para a serie de energia com todos os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import shapiro\n",
    "from pmdarima import auto_arima\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Capturar avisos de convergência e tratá-los\n",
    "warnings.filterwarnings(\"error\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados de energia e garantir que não há valores ausentes\n",
    "energia = pd.read_excel(\"energia.xlsx\", usecols=[1]).dropna()\n",
    "\n",
    "# In[223]: Criar a série temporal a partir de 1979 com frequência mensal\n",
    "energia.index = pd.date_range(start='1979-01', periods=len(energia), freq='M')\n",
    "energia = energia.squeeze()  # Converter para uma Series\n",
    "\n",
    "# In[224]: Separar a base de dados em treino e teste\n",
    "benergia = energia[:'2022-06'].ffill()  # Preencher valores nulos com forward fill\n",
    "reaisenergia = energia['2022-07':'2024-06']  # Teste de 2022-07 até 2024-06\n",
    "\n",
    "# In[225]: Converter explicitamente para tipo numérico e garantir que são floats\n",
    "benergia = pd.to_numeric(benergia, errors='coerce').astype(float)\n",
    "\n",
    "# In[226]: Lista para armazenar os modelos, MAPE e previsões\n",
    "modelos_energia = []\n",
    "mapes_energia = []\n",
    "previsoes_energia = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Naive\n",
    "naive_forecast = pd.Series([benergia.iloc[-1]] * len(reaisenergia), index=reaisenergia.index)\n",
    "mape_naive = mape(reaisenergia, naive_forecast) * 100\n",
    "modelos_energia.append(\"Naive\")\n",
    "mapes_energia.append(mape_naive)\n",
    "previsoes_energia[\"Naive\"] = naive_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Mean (média)\n",
    "mean_forecast = pd.Series(benergia.mean(), index=reaisenergia.index)\n",
    "mape_mean = mape(reaisenergia, mean_forecast) * 100\n",
    "modelos_energia.append(\"Mean\")\n",
    "mapes_energia.append(mape_mean)\n",
    "previsoes_energia[\"Mean\"] = mean_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Drift\n",
    "n = len(benergia)\n",
    "drift_slope = (benergia.iloc[-1] - benergia.iloc[0]) / (n - 1)\n",
    "drift_forecast = benergia.iloc[-1] + drift_slope * np.arange(1, len(reaisenergia) + 1)\n",
    "drift_forecast = pd.Series(drift_forecast, index=reaisenergia.index)\n",
    "mape_drift_result = mape(reaisenergia, drift_forecast) * 100\n",
    "modelos_energia.append(\"Drift\")\n",
    "mapes_energia.append(mape_drift_result)\n",
    "previsoes_energia[\"Drift\"] = drift_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Naive Sazonal\n",
    "naive_sazonal_forecast = pd.Series([benergia.iloc[-12 + (i % 12)]\n",
    "                                    for i in range(len(reaisenergia))],\n",
    "                                   index=reaisenergia.index)\n",
    "mape_naive_sazonal = mape(reaisenergia, naive_sazonal_forecast) * 100\n",
    "modelos_energia.append(\"Naive Sazonal\")\n",
    "mapes_energia.append(mape_naive_sazonal)\n",
    "previsoes_energia[\"Naive Sazonal\"] = naive_sazonal_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suavização Exponencial Simples (SES)\n",
    "ses_model = SimpleExpSmoothing(benergia).fit(optimized=True)\n",
    "ses_forecast = ses_model.forecast(steps=len(reaisenergia))\n",
    "mape_ses = mape(reaisenergia, ses_forecast) * 100\n",
    "modelos_energia.append(\"SES\")\n",
    "mapes_energia.append(mape_ses)\n",
    "previsoes_energia[\"SES\"] = ses_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt-Winters Aditivo - Ajustar inicialização e Box-Cox para melhorar a convergência\n",
    "try:\n",
    "    hw_add_model = ExponentialSmoothing(\n",
    "        benergia,\n",
    "        seasonal_periods=12,\n",
    "        trend='add',\n",
    "        seasonal='add',\n",
    "        initialization_method=\"estimated\",  # Método robusto de inicialização\n",
    "        use_boxcox=True  # Tentar estabilizar a variância com Box-Cox\n",
    "    ).fit(optimized=True)\n",
    "\n",
    "    hw_add_forecast = hw_add_model.forecast(steps=len(reaisenergia))\n",
    "    mape_hw_add = mape(reaisenergia, hw_add_forecast) * 100\n",
    "    modelos_energia.append(\"Holt-Winters Aditivo\")\n",
    "    mapes_energia.append(mape_hw_add)\n",
    "    previsoes_energia[\"Holt-Winters Aditivo\"] = hw_add_forecast\n",
    "except Exception:\n",
    "    modelos_energia.append(\"Holt-Winters Aditivo\")\n",
    "    mapes_energia.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holt-Winters Multiplicativo - Ajustar inicialização e Box-Cox para melhorar a convergência\n",
    "try:\n",
    "    hw_mult_model = ExponentialSmoothing(\n",
    "        benergia,\n",
    "        seasonal_periods=12,\n",
    "        trend='add',\n",
    "        seasonal='mul',\n",
    "        initialization_method=\"estimated\",  # Método robusto de inicialização\n",
    "        use_boxcox=True  # Tentar estabilizar a variância com Box-Cox\n",
    "    ).fit(optimized=True)\n",
    "\n",
    "    hw_mult_forecast = hw_mult_model.forecast(steps=len(reaisenergia))\n",
    "    mape_hw_mult = mape(reaisenergia, hw_mult_forecast) * 100\n",
    "    modelos_energia.append(\"Holt-Winters Multiplicativo\")\n",
    "    mapes_energia.append(mape_hw_mult)\n",
    "    previsoes_energia[\"Holt-Winters Multiplicativo\"] = hw_mult_forecast\n",
    "except Exception:\n",
    "    modelos_energia.append(\"Holt-Winters Multiplicativo\")\n",
    "    mapes_energia.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo ARIMA/SARIMA - Identificação automática\n",
    "try:\n",
    "    arima_model = auto_arima(benergia, seasonal=True, m=12, stepwise=True, trace=False, suppress_warnings=True)\n",
    "\n",
    "    # Exibir o melhor modelo ARIMA/SARIMA encontrado\n",
    "    print(f\"Melhor modelo ARIMA/SARIMA identificado: {arima_model}\")\n",
    "\n",
    "    arima_forecast = pd.Series(arima_model.predict(n_periods=len(reaisenergia)), index=reaisenergia.index)\n",
    "    mape_arima = mape(reaisenergia, arima_forecast) * 100\n",
    "    modelos_energia.append(\"ARIMA/SARIMA\")\n",
    "    mapes_energia.append(mape_arima)\n",
    "    previsoes_energia[\"ARIMA/SARIMA\"] = arima_forecast\n",
    "except Exception as e:\n",
    "    print(f\"Erro no modelo ARIMA/SARIMA: {e}\")\n",
    "    modelos_energia.append(\"ARIMA/SARIMA\")\n",
    "    mapes_energia.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação dos modelos com base no MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_comparison = pd.DataFrame({'Modelo': modelos_energia, 'MAPE': mapes_energia})\n",
    "mape_comparison = mape_comparison.sort_values(by='MAPE', ascending=True).reset_index(drop=True)\n",
    "print(mape_comparison)\n",
    "\n",
    "# In[236]: Gráfico dos MAPE dos modelos\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(mape_comparison['Modelo'], mape_comparison['MAPE'], color='skyblue')\n",
    "plt.xlabel(\"MAPE\")\n",
    "plt.title(\"MAPE Comparação de Modelos\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[237]: Selecionar o modelo com o menor MAPE\n",
    "melhor_modelo = mape_comparison.loc[0, 'Modelo']\n",
    "melhores_previsoes = previsoes_energia[melhor_modelo]\n",
    "\n",
    "# In[238]: Criar gráfico comparando os valores reais e previstos do melhor modelo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(reaisenergia.index, reaisenergia, label='Valores Reais', color='blue')\n",
    "plt.plot(reaisenergia.index, melhores_previsoes, label=f'Previsão - {melhor_modelo}', color='red')\n",
    "plt.title(f'Valores Reais vs Previsão ({melhor_modelo})')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Valores')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de normalidade e Ljung-Box para os resíduos do melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuos = reaisenergia - melhores_previsoes\n",
    "\n",
    "# In[240]: Teste de normalidade Shapiro-Wilk\n",
    "stat, p_value_shapiro = shapiro(residuos)\n",
    "print(f\"Teste de Normalidade Shapiro-Wilk: Estatística={stat:.4f}, p-valor={p_value_shapiro:.4f}\")\n",
    "if p_value_shapiro > 0.01:\n",
    "    print(\"Os resíduos parecem seguir uma distribuição normal (não rejeitamos H0).\")\n",
    "else:\n",
    "    print(\"Os resíduos não seguem uma distribuição normal (rejeitamos H0).\")\n",
    "\n",
    "# In[241]: Teste de Ljung-Box para autocorrelação dos resíduos\n",
    "lb_test = acorr_ljungbox(residuos, lags=[10], return_df=True)\n",
    "print(f\"Teste Ljung-Box:\\n{lb_test}\")\n",
    "\n",
    "# In[242]: Interpretação do teste de Ljung-Box\n",
    "p_value_ljungbox = lb_test['lb_pvalue'].values[0]\n",
    "if p_value_ljungbox > 0.01:\n",
    "    print(\"Não há evidências de autocorrelação significativa nos resíduos (não rejeitamos H0).\")\n",
    "else:\n",
    "    print(\"Há evidências de autocorrelação nos resíduos (rejeitamos H0).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usp-ds-series-temporais-TQD3F751",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
